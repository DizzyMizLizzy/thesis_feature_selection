defaults:
  - _self_
  - models: predictor  # Default to simple predictor model
  - datasets: MQ2008  # Default to MQ2008 dataset
  - train_mode: listwise  # Default to listwise training

# Training settings
global_mask: None
global_mask_ratio: 0
version: 0
mask_dir: None
mask_file: feature_importances.json
random_seed: 123
is_lassonet: False

# Device settings
device: cpu  # Changed from mps
gpus: 0

# Model settings
rank_loss: ${train_mode.rank_loss}
output_dim: 1

trainer:
  _target_: pytorch_lightning.Trainer
  detect_anomaly: True
  deterministic: True
  strategy: auto
  accelerator: ${device}
  devices: 1
  max_epochs: 20
  gradient_clip_val: 1.0  # Add gradient clipping
  limit_train_batches: 1.0
  default_root_dir: ${datasets.trained_fold}/${train_mode.mode}/${models.trained_fold}/${models.model_name}
  
  callbacks:
    - _target_: pytorch_lightning.callbacks.EarlyStopping
      monitor: validation_ndcg@10
      mode: max
      patience: 10
      verbose: True
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: validation_ndcg@10
      mode: max
      verbose: True
      save_top_k: 3

hydra:
  sweep:
    dir: multirun
    subdir: ${hydra.job.override_dirname}